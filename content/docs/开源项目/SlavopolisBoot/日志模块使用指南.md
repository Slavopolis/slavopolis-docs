# 日志模块使用指南

Slavopolis Boot 的日志模块是一个完整的日志解决方案，提供了结构化日志管理、链路追踪、性能监控、业务审计等核心功能。该模块基于 Logback 和 Spring Boot 构建，支持多种日志输出格式和目标，能够满足应用的日志管理需求。

## 核心特性

### 1. 链路追踪

每个请求都会生成唯一的 traceId 和 requestId，这些标识会贯穿整个请求处理链路，包括跨服务调用。通过 traceId 可以在分布式系统中追踪一个完整的业务流程，极大地简化了问题定位和性能分析。

### 2. 结构化日志

所有日志都以结构化的格式输出，包含时间戳、日志级别、线程信息、追踪标识、用户信息等关键字段。结构化日志便于日志收集系统（如 ELK Stack）进行解析和分析。

### 3. 性能监控

通过 `@LogPerformance` 注解可以自动监控方法的执行性能，记录执行时间、参数、返回值等信息。当方法执行时间超过阈值时，会自动记录警告日志，帮助及时发现性能问题。

### 4. 业务日志

通过 `@BusinessLog` 注解可以记录业务操作日志，支持 SpEL 表达式动态生成日志内容。业务日志包含操作人、操作时间、操作类型、操作结果等信息，满足审计和合规要求。

### 5. 访问日志

自动记录所有 HTTP 请求的详细信息，包括请求方法、URL、参数、响应状态、执行时间等。支持敏感信息脱敏，确保日志安全。

## 快速开始

### 1. 引入依赖

在项目的 pom.xml 中添加 common 模块依赖，日志功能会自动启用。

### 2. 配置 logback-spring.xml

将提供的 `logback-spring.xml` 文件放置在 `src/main/resources` 目录下。该配置文件已经包含了完整的日志配置，包括控制台输出、文件输出、异步日志、日志归档等功能。

### 3. 应用配置

在 `application.yml` 中添加日志相关配置：

```yaml
# 应用基础配置
spring:
  application:
    name: your-application-name

# 日志配置
logging:
  level:
    root: INFO
    club.slavopolis: DEBUG
  file:
    path: ./logs
  logback:
    rollingpolicy:
      max-history: 30
      max-file-size: 100MB
      total-size-cap: 10GB

# Common 日志模块配置
common:
  log:
    enabled: true
    exclude-patterns:
      - /actuator/**
      - /swagger-ui/**
      - /v3/api-docs/**
    access:
      enabled: true
      log-request-body: true
      log-response-body: false
      max-payload-length: 2048
      slow-request-threshold: 3000
    performance:
      enabled: true
      default-slow-threshold: 1000
      log-args: true
      log-result: false
    business:
      enabled: true
      async: true
      queue-size: 1024
```

## 使用示例

### 1. 基础日志使用

```java
import lombok.extern.slf4j.Slf4j;

@Slf4j
@RestController
public class UserController {
    
    @GetMapping("/users/{id}")
    public User getUser(@PathVariable Long id) {
        // 日志会自动包含 traceId
        log.info("Getting user by id: {}", id);
        
        try {
            User user = userService.findById(id);
            log.debug("Found user: {}", user);
            return user;
        } catch (Exception e) {
            // 错误日志会记录完整的异常堆栈
            log.error("Failed to get user: {}", id, e);
            throw e;
        }
    }
}
```

### 2. 性能监控

```java
@Service
@Slf4j
public class OrderService {
    
    @LogPerformance(
        slowThreshold = 2000,  // 2秒为慢操作
        logArgs = true,
        logResult = true,
        description = "创建订单"
    )
    public Order createOrder(OrderRequest request) {
        // 方法执行时间会自动记录
        // 超过阈值会输出警告日志
        return orderRepository.save(order);
    }
    
    @LogPerformance(slowThreshold = 5000)
    public void batchProcess(List<Long> orderIds) {
        // 批量处理通常耗时较长，设置更高的阈值
        orderIds.forEach(this::processOrder);
    }
}
```

### 3. 业务日志

```java
@RestController
@RequestMapping("/api/users")
public class UserManagementController {
    
    @PostMapping
    @BusinessLog(
        module = "用户管理",
        type = OperationType.CREATE,
        description = "创建用户: #{#request.username}"
    )
    public User createUser(@RequestBody @Valid UserRequest request) {
        return userService.create(request);
    }
    
    @PutMapping("/{id}")
    @BusinessLog(
        module = "用户管理",
        type = OperationType.UPDATE,
        description = "更新用户信息: ID=#{#id}, 更新字段=#{#request.updatedFields}"
    )
    public User updateUser(@PathVariable Long id, @RequestBody UserUpdateRequest request) {
        return userService.update(id, request);
    }
    
    @DeleteMapping("/{id}")
    @BusinessLog(
        module = "用户管理",
        type = OperationType.DELETE,
        description = "删除用户: #{#id}",
        logResult = true
    )
    public void deleteUser(@PathVariable Long id) {
        userService.delete(id);
    }
}
```

### 4. 手动添加追踪信息

```java
@Service
public class PaymentService {
    
    public PaymentResult processPayment(PaymentRequest request) {
        // 手动添加业务相关的追踪信息
        MDC.put("orderId", request.getOrderId());
        MDC.put("paymentMethod", request.getMethod());
        
        try {
            // 这些信息会出现在后续的所有日志中
            log.info("Processing payment for order: {}", request.getOrderId());
            
            PaymentResult result = paymentGateway.process(request);
            
            MDC.put("paymentStatus", result.getStatus());
            log.info("Payment processed successfully");
            
            return result;
        } finally {
            // 清理添加的 MDC 信息
            MDC.remove("orderId");
            MDC.remove("paymentMethod");
            MDC.remove("paymentStatus");
        }
    }
}
```

### 5. 跨服务追踪

```java
@Component
public class RestTemplateConfig {
    
    @Bean
    public RestTemplate restTemplate() {
        RestTemplate restTemplate = new RestTemplate();
        
        // 添加拦截器，传递 traceId
        restTemplate.getInterceptors().add((request, body, execution) -> {
            String traceId = MDC.get(CommonConstants.TRACE_ID);
            if (traceId != null) {
                request.getHeaders().add(HttpConstants.HEADER_TRACE_ID, traceId);
            }
            return execution.execute(request, body);
        });
        
        return restTemplate;
    }
}

// Feign 客户端配置
@Component
public class FeignTraceInterceptor implements RequestInterceptor {
    
    @Override
    public void apply(RequestTemplate template) {
        String traceId = MDC.get(CommonConstants.TRACE_ID);
        if (traceId != null) {
            template.header(HttpConstants.HEADER_TRACE_ID, traceId);
        }
    }
}
```

## 日志级别规范

### 1. ERROR 级别

用于记录系统错误和异常，需要立即关注和处理的问题：

- 未捕获的异常
- 外部服务调用失败
- 数据库操作失败
- 关键业务流程失败

```java
log.error("Database connection failed", exception);
log.error("Payment gateway timeout for order: {}", orderId, exception);
```

### 2. WARN 级别

用于记录警告信息，可能影响系统功能但不会导致失败：

- 性能问题（响应时间过长）
- 使用了废弃的 API
- 配置问题但有默认值
- 重试操作

```java
log.warn("API response time exceeded threshold: {}ms", duration);
log.warn("Retrying failed operation, attempt: {}", retryCount);
```

### 3. INFO 级别

用于记录重要的业务流程和状态变化：

- 应用启动/关闭
- 重要业务操作
- 状态变更
- 外部服务调用

```java
log.info("Application started successfully on port: {}", port);
log.info("User {} logged in from IP: {}", username, ipAddress);
log.info("Order {} status changed from {} to {}", orderId, oldStatus, newStatus);
```

### 4. DEBUG 级别

用于记录详细的调试信息，生产环境通常关闭：

- 方法入参和返回值
- 中间计算结果
- SQL 语句
- 详细的流程信息

```java
log.debug("Calculating discount for user: {}, items: {}", userId, items);
log.debug("SQL query result: {}", result);
```

### 5. TRACE 级别

用于记录最详细的信息，通常只在排查特定问题时开启：

- 方法调用栈
- 详细的数据变化
- 循环内的操作

java

```java
log.trace("Entering method: {}", methodName);
log.trace("Processing item {} of {}", index, total);
```

## 最佳实践

### 1. 日志内容规范

```java
// ✅ 好的实践：包含上下文信息
log.info("Order created successfully - orderId: {}, userId: {}, amount: {}", 
         orderId, userId, amount);

// ❌ 不好的实践：缺少上下文
log.info("Order created");

// ✅ 好的实践：使用占位符
log.debug("Processing {} items for user {}", items.size(), userId);

// ❌ 不好的实践：字符串拼接
log.debug("Processing " + items.size() + " items for user " + userId);
```

### 2. 异常日志记录

```java
// ✅ 好的实践：记录异常的上下文
try {
    processOrder(orderId);
} catch (Exception e) {
    log.error("Failed to process order - orderId: {}, userId: {}", 
              orderId, userId, e);
    throw new BusinessException("订单处理失败", e);
}

// ❌ 不好的实践：只记录异常消息
catch (Exception e) {
    log.error(e.getMessage());
}
```

### 3. 敏感信息处理

```java
// ✅ 好的实践：脱敏处理
log.info("User login - username: {}, mobile: {}", 
         username, maskMobile(mobile));

// ❌ 不好的实践：直接记录敏感信息
log.info("User login - username: {}, password: {}", 
         username, password);

// 脱敏工具方法
private String maskMobile(String mobile) {
    if (mobile == null || mobile.length() < 11) {
        return mobile;
    }
    return mobile.substring(0, 3) + "****" + mobile.substring(7);
}
```

### 4. 性能考虑

```java
// ✅ 好的实践：先检查日志级别
if (log.isDebugEnabled()) {
    log.debug("Heavy computation result: {}", expensiveOperation());
}

// ❌ 不好的实践：总是执行耗时操作
log.debug("Heavy computation result: {}", expensiveOperation());

// ✅ 好的实践：使用 Supplier 延迟计算
log.debug("Result: {}", () -> complexCalculation());
```

### 5. MDC 使用

```java
@Component
public class MdcUtils {
    
    public static void setBusinessContext(String businessId, String businessType) {
        MDC.put("businessId", businessId);
        MDC.put("businessType", businessType);
    }
    
    public static void clearBusinessContext() {
        MDC.remove("businessId");
        MDC.remove("businessType");
    }
    
    // 使用 try-with-resources 模式
    public static Closeable withContext(String key, String value) {
        MDC.put(key, value);
        return () -> MDC.remove(key);
    }
}

// 使用示例
try (var ignored = MdcUtils.withContext("orderId", orderId)) {
    // 在这个块中的所有日志都会包含 orderId
    processOrder();
}
```

## 日志分析和监控

### 1. 日志文件说明

- **{app}-all.log**: 包含所有级别的日志，用于问题排查
- **{app}-error.log**: 只包含 ERROR 级别日志，用于快速定位错误
- **{app}-business.log**: 业务操作日志，用于审计和分析
- **{app}-performance.log**: 性能监控日志，用于性能优化
- **{app}-access.log**: HTTP 访问日志，用于流量分析
- **{app}-json.log**: JSON 格式日志，用于 ELK 等日志系统

### 2. 日志查询示例

```bash
# 查找特定 traceId 的所有日志
grep "traceId-12345" logs/app-all.log

# 查找特定用户的操作
grep "userId:10001" logs/app-business.log

# 查找慢请求
grep "SLOW" logs/app-performance.log

# 查找特定时间段的错误
grep "2025-01-01 14:" logs/app-error.log

# 使用 jq 分析 JSON 日志
cat logs/app-json.log | jq 'select(.level=="ERROR") | {time:.timestamp, error:.message}'
```

### 3. 集成 ELK Stack

JSON 格式的日志可以直接被 Logstash 采集：

```yaml
# logstash.conf
input {
  file {
    path => "/app/logs/*-json.log"
    codec => "json"
    type => "application-log"
  }
}

filter {
  if [type] == "application-log" {
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
      target => "@timestamp"
    }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "app-logs-%{+YYYY.MM.dd}"
  }
}
```

## 故障排查

### 1. 日志不输出

检查日志级别配置：

```yaml
logging:
  level:
    club.slavopolis: DEBUG  # 确保包名正确
```

### 2. 日志文件过大

调整滚动策略：

```yaml
logging:
  logback:
    rollingpolicy:
      max-file-size: 50MB  # 减小单个文件大小
      max-history: 7       # 减少保留天数
```

### 3. 性能影响

使用异步日志：

```xml
<!-- 在 logback-spring.xml 中已配置异步 appender -->
<appender name="ASYNC_FILE_ALL" class="ch.qos.logback.classic.AsyncAppender">
    <queueSize>2048</queueSize>
    <discardingThreshold>0</discardingThreshold>
    <appender-ref ref="FILE_ALL"/>
</appender>
```

## 总结

本日志模块提供了完整的企业级日志解决方案，通过合理使用各项功能，可以：

1. **快速定位问题**：通过 traceId 追踪完整的请求链路
2. **监控系统性能**：自动记录方法执行时间和慢操作
3. **满足审计要求**：完整记录业务操作日志
4. **支持日志分析**：结构化日志便于统计分析
5. **保证日志安全**：自动脱敏敏感信息

遵循本指南的最佳实践，可以构建一个高效、可靠的日志体系，为系统的稳定运行提供有力保障。